{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/Users/dawidkubicki/Documents/datasets/digit-recognizer/train.csv')\n",
    "test_data = pd.read_csv('/Users/dawidkubicki/Documents/datasets/digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"label\"].to_numpy()\n",
    "x_train = train_data.drop(columns=[\"label\"]).to_numpy()\n",
    "\n",
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "y_train = y_train[..., tf.newaxis].astype(\"float32\")\n",
    "\n",
    "\n",
    "test_data = test_data.to_numpy()\n",
    "test_data = test_data[..., tf.newaxis].astype(\"float32\")\n",
    "\n",
    "x_train, test_data = x_train.reshape((-1, 28, 28, 1)), test_data.reshape((-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [9.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa7e571a310>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 14\n",
    "\n",
    "print(y_train[index])\n",
    "plt.imshow(x_train[index].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(64)\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid)).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(FashNet, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxp1 = tf.keras.layers.MaxPooling2D()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxp2 = tf.keras.layers.MaxPooling2D()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.d1 = tf.keras.layers.Dense(256, activation='relu')\n",
    "        self.d2 = tf.keras.layers.Dense(10, activation='sigmoid')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxp1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxp2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "    \n",
    "model = FashNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "opt = tf.keras.optimizers.RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test step\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(images, training=True)\n",
    "        loss = loss_func(labels, pred)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid step\n",
    "def valid_step(images, labels):\n",
    "    pred = model(images, training=False)\n",
    "    loss = loss_func(labels, pred)\n",
    "    \n",
    "    valid_loss(loss)\n",
    "    valid_accuracy(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,Loss 1.3185412883758545, Accuracy 89.65178680419922, Valid Loss: 0.09535414725542068,Valid Accuracy: 97.38095092773438\n",
      "Epoch 2,Loss 0.08076469600200653, Accuracy 97.56547546386719, Valid Loss: 0.10326319932937622,Valid Accuracy: 97.38690185546875\n",
      "Epoch 3,Loss 0.049776215106248856, Accuracy 98.39285278320312, Valid Loss: 0.10410693287849426,Valid Accuracy: 97.52381134033203\n",
      "Epoch 4,Loss 0.03387067839503288, Accuracy 98.97917175292969, Valid Loss: 0.10208946466445923,Valid Accuracy: 97.67857360839844\n",
      "Epoch 5,Loss 0.02782743237912655, Accuracy 99.1577377319336, Valid Loss: 0.1059032455086708,Valid Accuracy: 97.70713806152344\n",
      "Epoch 6,Loss 0.02512703835964203, Accuracy 99.16666412353516, Valid Loss: 0.11008866876363754,Valid Accuracy: 97.78372955322266\n",
      "Epoch 7,Loss 0.021274488419294357, Accuracy 99.25892639160156, Valid Loss: 0.11321703344583511,Valid Accuracy: 97.84183502197266\n",
      "Epoch 8,Loss 0.01978609897196293, Accuracy 99.30952453613281, Valid Loss: 0.11677627265453339,Valid Accuracy: 97.88542175292969\n",
      "Epoch 9,Loss 0.02000689134001732, Accuracy 99.3125, Valid Loss: 0.12213402986526489,Valid Accuracy: 97.88756561279297\n",
      "Epoch 10,Loss 0.015173608437180519, Accuracy 99.42262268066406, Valid Loss: 0.12678509950637817,Valid Accuracy: 97.90238189697266\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "        \n",
    "    for images, labels in valid_ds:\n",
    "        valid_step(images, labels)\n",
    "        \n",
    "    print(\n",
    "            f'Epoch {epoch+1},'\n",
    "            f'Loss {train_loss.result()}, '\n",
    "            f'Accuracy {train_accuracy.result() * 100}, '\n",
    "            f'Valid Loss: {valid_loss.result()},'\n",
    "            f'Valid Accuracy: {valid_accuracy.result() *100}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]],\n",
       "\n",
       "\n",
       "        [[[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]],\n",
       "\n",
       "         [[0.]]]]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
