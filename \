#tensorflow subclassing API


import tensorflow as tf
gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    print('gpu', gpu)
    tf.config.experimental.set_memory_growth(gpu, True)
    print('memory growth:' , tf.config.experimental.get_memory_growth(gpu))

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

x_train = x_train[..., tf.newaxis].astype("float32")
x_test = x_test[..., tf.newaxis].astype("float32")

#batch and shuffle data
train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)

test_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)


#model with init and call
class MyModel(tf.keras.Model):
	def __init__(self):
		super(MyModel, self).__init__()
		self.conv1 = tf.keras.layers.Conv2D(32, 3, activation="relu")
		self.flatten = tf.keras.layers.Flatten()
		self.d1 = tf.keras.layers.Dense(128, activation="relu")
		self.d2 = tf.keras.layers.Dense(1, activation="sigmoid")
	def call(self, x):
		x = self.conv1(x)
		x = self.flatten(x)
		x = self.d1(x)
		return self.d2(x)

model = MyModel()

#optimizer and loss function

loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)
optimizer = tf.keras.optimizers.Adam()

#loss and accuracy metrics

train_loss = tf.keras.metrics.mean(name="train_loss")
train_accuracy = tf.keras.sparsecategoricalaccuracy(name="train_accuracy")

test_loss = tf.keras.metrics.mean(name="test_loss")
test_accuracy = tf.keras.SparseCategoricalAcccuracy(name="test_accuracy")


